{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('../input/train.csv')\n",
    "test=pd.read_csv('../input/test.csv')\n",
    "alldata=train.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "severity_type.csv log_feature.csv resource_type.csv event_type.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for f in os.listdir('../input'):\n",
    "    if 'sample' in f or 'train' in f or 'test' in f:\n",
    "        continue\n",
    "    tmp=pd.read_csv('../input/'+f)\n",
    "    alldata=pd.merge(alldata,tmp,on='id',how='left')\n",
    "    print f,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fault_severity</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>severity_type</th>\n",
       "      <th>log_feature</th>\n",
       "      <th>volume</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>event_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14121</td>\n",
       "      <td>location 118</td>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>feature 312</td>\n",
       "      <td>19</td>\n",
       "      <td>resource_type 2</td>\n",
       "      <td>event_type 34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9320</td>\n",
       "      <td>location 91</td>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>feature 315</td>\n",
       "      <td>200</td>\n",
       "      <td>resource_type 2</td>\n",
       "      <td>event_type 34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>14394</td>\n",
       "      <td>location 152</td>\n",
       "      <td>severity_type 2</td>\n",
       "      <td>feature 221</td>\n",
       "      <td>1</td>\n",
       "      <td>resource_type 2</td>\n",
       "      <td>event_type 35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>8218</td>\n",
       "      <td>location 931</td>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>feature 80</td>\n",
       "      <td>9</td>\n",
       "      <td>resource_type 8</td>\n",
       "      <td>event_type 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>14804</td>\n",
       "      <td>location 120</td>\n",
       "      <td>severity_type 1</td>\n",
       "      <td>feature 134</td>\n",
       "      <td>1</td>\n",
       "      <td>resource_type 2</td>\n",
       "      <td>event_type 34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fault_severity     id      location    severity_type  log_feature  volume  \\\n",
       "0                1  14121  location 118  severity_type 2  feature 312      19   \n",
       "4                0   9320   location 91  severity_type 2  feature 315     200   \n",
       "8                1  14394  location 152  severity_type 2  feature 221       1   \n",
       "12               1   8218  location 931  severity_type 1   feature 80       9   \n",
       "18               0  14804  location 120  severity_type 1  feature 134       1   \n",
       "\n",
       "      resource_type     event_type  \n",
       "0   resource_type 2  event_type 34  \n",
       "4   resource_type 2  event_type 34  \n",
       "8   resource_type 2  event_type 35  \n",
       "12  resource_type 8  event_type 15  \n",
       "18  resource_type 2  event_type 34  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata=alldata.drop_duplicates(subset='id')\n",
    "alldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fault_severity (3,)\n",
      "id (18552,)\n",
      "location (1126,)\n",
      "severity_type (5,)\n",
      "log_feature (272,)\n",
      "volume (215,)\n",
      "resource_type (10,)\n",
      "event_type (49,)\n"
     ]
    }
   ],
   "source": [
    "for i in alldata.columns.values:\n",
    "    print i,alldata[i].value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fault_severity</th>\n",
       "      <th>id</th>\n",
       "      <th>location</th>\n",
       "      <th>severity_type</th>\n",
       "      <th>log_feature</th>\n",
       "      <th>volume</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>event_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14121</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>312</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9320</td>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>315</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>14394</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>221</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>8218</td>\n",
       "      <td>931</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>14804</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fault_severity     id  location  severity_type  log_feature  volume  \\\n",
       "0                1  14121       118              2          312      19   \n",
       "4                0   9320        91              2          315     200   \n",
       "8                1  14394       152              2          221       1   \n",
       "12               1   8218       931              1           80       9   \n",
       "18               0  14804       120              1          134       1   \n",
       "\n",
       "    resource_type  event_type  \n",
       "0               2          34  \n",
       "4               2          34  \n",
       "8               2          35  \n",
       "12              8          15  \n",
       "18              2          34  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getfea(ds):\n",
    "    return ds.map(str).apply(lambda x:x.split()[-1]).astype(float)\n",
    "for i in alldata.columns.values:\n",
    "    alldata[i]=getfea(alldata[i])\n",
    "alldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.merge(train[['id']],alldata,on='id',how='left')\n",
    "test=pd.merge(test[['id']],alldata,on='id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv('train1.csv',index=False)\n",
    "test.to_csv('test1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#alldata['log-volume']=alldata['log_feature'].map(str)+'_'+alldata['volume'].map(str)\n",
    "alldata['sr']=alldata.severity_type.map(str)+'_'+alldata.resource_type.map(str)\n",
    "alldata['er']=alldata.event_type.map(str)+'_'+alldata.resource_type.map(str)\n",
    "alldata['es']=alldata.event_type.map(str)+'_'+alldata.severity_type.map(str)\n",
    "alldata['lr']=alldata.log_feature.map(str)+'_'+alldata.resource_type.map(str)\n",
    "alldata['le']=alldata.log_feature.map(str)+'_'+alldata.event_type.map(str)\n",
    "alldata['ls']=alldata.log_feature.map(str)+'_'+alldata.severity_type.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fault_severity (3,)\n",
      "id (18552,)\n",
      "location (1126,)\n",
      "severity_type (5,)\n",
      "log_feature (272,)\n",
      "volume (215,)\n",
      "resource_type (10,)\n",
      "event_type (49,)\n",
      "sr (28,)\n",
      "er (132,)\n",
      "es (98,)\n",
      "lr (490,)\n",
      "le (737,)\n",
      "ls (451,)\n"
     ]
    }
   ],
   "source": [
    "for i in alldata.columns.values:\n",
    "    print i,alldata[i].value_counts().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "def onehot(dtrain,dtest):\n",
    "    vec = DictVectorizer()\n",
    "    X_sparse = vec.fit_transform(dtrain.T.to_dict().values())\n",
    "    Xt_sparse = vec.transform(dtest.T.to_dict().values())\n",
    "    return X_sparse,Xt_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7381, 27) (11171, 27)\n"
     ]
    }
   ],
   "source": [
    "train=pd.merge(train[['id']],alldata,on='id',how='left')\n",
    "test=pd.merge(test[['id']],alldata,on='id',how='left')\n",
    "X,Xt=onehot(train[['sr']],test[['sr']])\n",
    "import pickle\n",
    "print X.shape,Xt.shape\n",
    "pickle.dump(X,open('X1.p','w'))\n",
    "pickle.dump(Xt,open('Xt1.p','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7381, 212) (11171, 212)\n"
     ]
    }
   ],
   "source": [
    "train=pd.merge(train[['id']],alldata,on='id',how='left')\n",
    "test=pd.merge(test[['id']],alldata,on='id',how='left')\n",
    "X,Xt=onehot(train[['sr','es','er']],test[['sr','es','er']])\n",
    "import pickle\n",
    "print X.shape,Xt.shape\n",
    "pickle.dump(X,open('X2.p','w'))\n",
    "pickle.dump(Xt,open('Xt2.p','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7381, 1407) (11171, 1407)\n"
     ]
    }
   ],
   "source": [
    "feas=['sr','es','er','le','lr','ls']\n",
    "train=pd.merge(train[['id']],alldata,on='id',how='left')\n",
    "test=pd.merge(test[['id']],alldata,on='id',how='left')\n",
    "X,Xt=onehot(train[feas],test[feas])\n",
    "import pickle\n",
    "print X.shape,Xt.shape\n",
    "pickle.dump(X,open('X3.p','w'))\n",
    "pickle.dump(Xt,open('Xt3.p','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
